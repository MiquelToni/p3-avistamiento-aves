{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 Avistamiento de aves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener datos (scraping)\n",
    "\n",
    "Primero vamos a obtener los datos. Para ello nos visitaremos las web de avistamientos de aves [shorebirder](https://www.shorebirder.com/), [trevorsbirding](https://www.trevorsbirding.com/) y [dantallmansbirdblog](https://dantallmansbirdblog.blogspot.com/).\n",
    "\n",
    "Durante la visita a la web y haciendo uso del inspector (F12) podemos ver que las descripciones que necesitamos se encuentran en los tag de párrafo (entre *\\<p\\> TEXTO \\</p\\>*). Sabiendo eso vamos a crear funciones de utilidad que se encargarán de descargar el contenido de la web y extraer el texto.\n",
    "\n",
    "Las descargas las realizaremos en `data/raw` mientras que en `data/posts` guardaremos los textos encontrados.\n",
    "\n",
    "** `dantallmansbirdblog` tiene una estructura ligeramente diferente (entre *\\<p\\>\\</p\\> TEXTO \\<p\\>\\</p\\>*), a lo que tendremos que modificar la función `get_texts` (a continuación) para obtener sus textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O utils\n",
    "import os\n",
    "from os.path import exists\n",
    "import re\n",
    "import wget\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "# auxiliar regex\n",
    "remove_parentesis_text = re.compile(r'\\(.*\\)')\n",
    "sentence_endings = re.compile(r'\\.|\\*')\n",
    "\n",
    "# auxiliar functions\n",
    "def maybe_mkdir(path):\n",
    "  try:\n",
    "    if not exists(path):\n",
    "      os.mkdir(path)\n",
    "  except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "def download(url, out_label):\n",
    "  filepath = f\"{data_raw_path}/{out_label}\"\n",
    "  if exists(filepath):\n",
    "    os.remove(filepath)\n",
    "  return wget.download(url, out=filepath)\n",
    "\n",
    "def get_texts(filename):\n",
    "  file = open(filename, 'r')\n",
    "  text = file.read()\n",
    "  file.close()\n",
    "\n",
    "  # get texts\n",
    "  get_p = re.compile(r'<p>((.|\\n)*?)</p>')\n",
    "  texts = get_p.findall(text)\n",
    "\n",
    "  # remove styling and inner tags\n",
    "  remove_tags = re.compile(r'(<.*?>)|\\\\n| +(?= )|\\\\|\\&.+?\\;')\n",
    "  return map(lambda text: re.sub(remove_tags, \"\", str(text[0]).lower()), texts)\n",
    "\n",
    "def write(path, filename, data):\n",
    "  filepath = f\"{path}/{filename}.txt\"\n",
    "  file = open(filepath, \"w\", encoding=\"utf-8\")\n",
    "  for item in data:\n",
    "    file.write(str(item)+\"\\n\")\n",
    "  file.close()\n",
    "  return filepath\n",
    "\n",
    "def save_json(path, filename, dict):\n",
    "  filepath = f\"{path}/{filename}.json\"\n",
    "  # create json object from dictionary\n",
    "  parsed_json = json.dumps(dict)\n",
    "  f = open(filepath,\"w\")\n",
    "  # write json object to file\n",
    "  f.write(parsed_json)\n",
    "  # close file\n",
    "  f.close()\n",
    "  return filepath\n",
    "\n",
    "# constants\n",
    "data_posts_cache = \"../data/cache\" # guardar resultados de queries a sparql\n",
    "data_raw_path = \"../data/raw\" # descargas\n",
    "data_posts_path = \"../data/posts\" # guardar los textos de los post scrapeados\n",
    "data_results_path = \"../data/results\" # guardar los resultados de las diferentes pruebas\n",
    "\n",
    "# build directory structure\n",
    "maybe_mkdir(\"../models\")\n",
    "maybe_mkdir(\"../models/entity_ruler\")\n",
    "maybe_mkdir(\"../data\")\n",
    "maybe_mkdir(\"../owl\")\n",
    "maybe_mkdir(data_raw_path)\n",
    "maybe_mkdir(data_posts_path)\n",
    "maybe_mkdir(data_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación haciendo uso de las funciones anteriores scrapeamos la home de `shorebirder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my late march solo visit to norway is in the books and was about as much fun as i've had in a while. the middle few days of the trip were spent birding around varanger, bookended by more touristy time intromsÃ£Â¸and oslo. at some point in the coming months there will be a full trip report here plus a very detailed cloudbirders submission. in the meantime, here is some proof that i actually went.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap shorebirder.com\n",
    "shorebirder_filename = \"shorebirder_home.html\"\n",
    "shorebirder_home = download(\"https://www.shorebirder.com/\", shorebirder_filename)\n",
    "posts = get_texts(shorebirder_home)\n",
    "shorebirder_posts_file = write(data_posts_path, shorebirder_filename, posts)\n",
    "\n",
    "open(shorebirder_posts_file, \"r\").readlines()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo para `trevorsbirding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'earlier this week i glanced out of my sunroom window to check whether there were any birds at my birdbaths. i currently have three birdbaths just outside the room, one on the ground, one on a pedestal at about 60cm and one hanging from a tree branch at a height of about 1.5 metres. i was delighted to see a small flock of purple-crowned lorikeets having a drink and dipping into the water for a bath. i have just checked my list of species to have visited the birdbaths. this was bird species number 36, in addition to the three reptiles and two mammal species.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap trevorsbirding.com\n",
    "trevorsbirding_filename = \"trevorsbirding_home.html\"\n",
    "trevorsbirding_home = download(\"https://www.trevorsbirding.com/\", trevorsbirding_filename)\n",
    "posts = get_texts(trevorsbirding_home)\n",
    "trevorsbirding_posts_file = write(data_posts_path, trevorsbirding_filename, posts)\n",
    "\n",
    "open(trevorsbirding_posts_file, \"r\").readlines()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento 1: Usar spacy sin modificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dependencias para el nlp\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    new haven\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ": come for the pizza, stay for the crime!</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " i was out messing with my brand new camera body, the canon \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    r5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       ", which at the time i had paired with my trusty ol' \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    400mm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " f5.6. i was walking back to the car at \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fort hale park\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " when i heard a &quot;thwack!&quot; right next to me followed by the most awful gull scream you've ever heard. i looked down to my left and a ring-billed gull was flailing a bloody, broken right wing. looking up i eventually located the culprit, a hefty adult (presumed) female peregrine falcon.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prueba\n",
    "for text in open(shorebirder_posts_file, \"r\").readlines()[3:5]:\n",
    "  train = nlp(text)\n",
    "  displacy.render(train, jupyter=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que es capaz de identificar diferentes entidades dentro de las frases, pero no pájaros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento 2: Usando sparql query para encontrar aves\n",
    "\n",
    "Idea: Usando el tokenizer de spacy como tokenizer trocear las frases. A partir de los token etiquetados como nombre (`NOUN`) lanzamos una petición a la dbpedia. Ya el resultado de la dbpedia nos dirá si existe y cual es su etiqueta / url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparQL class extension\n",
    "# Prefixes and Class based from https://github.com/ejrav/pydbpedia\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "class SparqlEndpoint(object):\n",
    "\n",
    "    def __init__(self, endpoint, prefixes={}):\n",
    "        self.sparql = SPARQLWrapper(endpoint)\n",
    "        self.prefixes = {\n",
    "            \"dbo\": \"http://dbpedia.org/ontology/\",\n",
    "            \"owl\": \"http://www.w3.org/2002/07/owl#\",\n",
    "            \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "            \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "            \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "            \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n",
    "            \"dc\": \"http://purl.org/dc/elements/1.1/\",\n",
    "            \"dbpedia2\": \"http://dbpedia.org/property/\",\n",
    "            \"dbpedia\": \"http://dbpedia.org/\",\n",
    "            \"skos\": \"http://www.w3.org/2004/02/skos/core#\",\n",
    "            \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n",
    "            \"yago\": \"http://dbpedia.org/class/yago/\",\n",
    "            }\n",
    "        self.prefixes.update(prefixes)\n",
    "        self.sparql.setReturnFormat(JSON)\n",
    "\n",
    "    def query(self, q):\n",
    "        lines = [\"PREFIX %s: <%s>\" % (k, r) for k, r in self.prefixes.items()]\n",
    "        lines.extend(q.split(\"\\n\"))\n",
    "        query = \"\\n\".join(lines)\n",
    "        self.sparql.setQuery(query)\n",
    "        results = self.sparql.query().convert()\n",
    "        return results[\"results\"][\"bindings\"]\n",
    "\n",
    "\n",
    "class DBpediaEndpoint(SparqlEndpoint):\n",
    "    def __init__(self, endpoint, prefixes = {}):\n",
    "        super(DBpediaEndpoint, self).__init__(endpoint, prefixes)\n",
    "\n",
    "s = DBpediaEndpoint(endpoint = \"http://dbpedia.org/sparql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bird': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Collared_falconet'},\n",
       "  'name': {'type': 'literal', 'xml:lang': 'en', 'value': 'Collared falconet'},\n",
       "  'comment': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'The collared falconet (Microhierax caerulescens) is a species of bird of prey in the family Falconidae. It is found in the Indian Subcontinent and Southeast Asia, ranging across Bangladesh, Bhutan, Cambodia, India, Laos, Myanmar, Nepal, Thailand, Malaysia, and Vietnam.Its natural habitat is temperate forest, often on the edges of broadleaf forest. It is 18 cm long. Rapid wingbeats are interspersed with long glides. When perched, it is described as being \"rather shrikelike.\"'}},\n",
       " {'bird': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Peregrine_falcon'},\n",
       "  'name': {'type': 'literal', 'xml:lang': 'en', 'value': 'Peregrine falcon'},\n",
       "  'comment': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'The peregrine falcon (Falco peregrinus), also known as the peregrine, and historically as the duck hawk in North America, is a cosmopolitan bird of prey (raptor) in the family Falconidae. A large, crow-sized falcon, it has a blue-grey back, barred white underparts, and a black head. The peregrine is renowned for its speed, reaching over 320 km/h (200 mph) during its characteristic hunting stoop (high-speed dive), making it the fastest bird in the world, as well as the fastest member of the animal kingdom. According to a National Geographic TV program, the highest measured speed of a peregrine falcon is 389 km/h (242 mph). As is typical for bird-eating raptors, peregrine falcons are sexually dimorphic, with females being considerably larger than males. The peregrine\\'s breeding range includes land regions from the Arctic tundra to the tropics. It can be found nearly everywhere on Earth, except extreme polar regions, very high mountains, and most tropical rainforests; the only major ice-free landmass from which it is entirely absent is New Zealand. This makes it the world\\'s most widespread raptor, and one of the most widely found bird species. In fact, the only land-based bird species found over a larger geographic area is not always naturally occurring, but one widely introduced by humans, the rock pigeon, which in turn now supports many peregrine populations as a prey species. The peregrine is a highly successful example of urban wildlife in much of its range, taking advantage of tall buildings as nest sites and an abundance of prey such as pigeons and ducks. Both the English and scientific names of this species mean \"wandering falcon,\" referring to the migratory habits of many northern populations. Experts recognize 17 to 19 subspecies, which vary in appearance and range; disagreement exists over whether the distinctive Barbary falcon is represented by two subspecies of Falco peregrinus, or is a separate species, F. pelegrinoides. The two species\\' divergence is relatively recent, during the time of the last ice age, therefore the genetic differential between them (and also the difference in their appearance) is relatively tiny. They are only about 0.6–0.8% genetically differentiated. Although its diet consists almost exclusively of medium-sized birds, the peregrine will sometimes hunt small mammals, small reptiles, or even insects. Reaching sexual maturity at one year, it mates for life and nests in a scrape, normally on cliff edges or, in recent times, on tall human-made structures. The peregrine falcon became an endangered species in many areas because of the widespread use of certain pesticides, especially DDT. Since the ban on DDT from the early 1970s, populations have recovered, supported by large-scale protection of nesting places and releases to the wild. The peregrine falcon is a well-respected falconry bird due to its strong hunting ability, high trainability, versatility, and availability via captive breeding. It is effective on most game bird species, from small to large. It has also been used as a religious, royal, or national symbol across multiple eras and areas of human civilization.'}},\n",
       " {'bird': {'type': 'uri',\n",
       "   'value': \"http://dbpedia.org/resource/Eleonora's_falcon\"},\n",
       "  'name': {'type': 'literal', 'xml:lang': 'en', 'value': \"Eleonora's falcon\"},\n",
       "  'comment': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': \"Eleonora's falcon (Falco eleonorae) is a medium-sized falcon. It belongs to the hobby group, a rather close-knit number of similar falcons often considered a subgenus Hypotriorchis. The sooty falcon is sometimes considered its closest relative, but while they certainly belong to the same lineage, they do not seem to be close sister species. The English name and the species name eleonorae commemorate Eleanor of Arborea, Queen or Lady-Judge (Juighissa) and national heroine of Sardinia, who in 1392, under the jurisdiction conferred by the Carta de Logu, became the first ruler in history to grant protection to hawk and falcon nests against illegal hunters. The genus name falco is from Late Latin falx, falcis, a sickle, referring to the claws of the bird.\"}},\n",
       " {'bird': {'type': 'uri',\n",
       "   'value': 'http://dbpedia.org/resource/Red-footed_falcon'},\n",
       "  'name': {'type': 'literal', 'xml:lang': 'en', 'value': 'Red-footed falcon'},\n",
       "  'comment': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': \"The red-footed falcon (Falco vespertinus), formerly the western red-footed falcon, is a bird of prey. It belongs to the family Falconidae, the falcons. This bird is found in eastern Europe and Asia although its numbers are dwindling rapidly due to habitat loss and hunting. It is migratory, wintering in Africa. It is a regular wanderer to western Europe, and in August 2004 a red-footed falcon was found in North America for the first time on the island of Martha's Vineyard, Massachusetts.\"}},\n",
       " {'bird': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Altai_falcon'},\n",
       "  'name': {'type': 'literal', 'xml:lang': 'en', 'value': 'Altai falcon'},\n",
       "  'comment': {'type': 'literal',\n",
       "   'xml:lang': 'en',\n",
       "   'value': 'The Altai falcon (Falco cherrug altaicus?) is a large falcon of questionable taxonomic position. It is often considered to be a subspecies of the saker falcon (Falco cherrug). It used to have a high reputation among Central Asian falconers. It is uncertain whether the bird is a saker subspecies or a hybrid.'}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para buscar una ave dado su nombre\n",
    "def search_bird_dbpedia(token):\n",
    "  return s.query('''\n",
    "    SELECT *\n",
    "    WHERE {\n",
    "      ?bird a dbo:Bird ;\n",
    "            rdfs:label ?name ;\n",
    "            dbo:abstract ?comment .\n",
    "\n",
    "      filter (!isLiteral(?name) ||\n",
    "              langmatches(lang(?name), \"en\")) .\n",
    "\n",
    "      filter (!isLiteral(?comment) ||\n",
    "              langmatches(lang(?comment), \"en\")) .\n",
    "\n",
    "      filter (CONTAINS(LCASE(STR(?name)), \"{token}\")) .\n",
    "    }\n",
    "    limit 5\n",
    "  '''.replace(\"{token}\", token))\n",
    "\n",
    "search_bird_dbpedia(\"falcon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n",
      "time\n",
      "ol'\n",
      "car\n",
      "gull\n",
      "ring\n",
      "gull\n",
      "wing\n",
      "peregrine\n",
      "falcon\n"
     ]
    }
   ],
   "source": [
    "# Prueba\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "maybe_matches = {}\n",
    "for text in open(shorebirder_posts_file, \"r\").readlines()[4:5]:\n",
    "  doc = nlp(text)\n",
    "  for chunk in doc.noun_chunks:\n",
    "    for token in chunk:\n",
    "      if token.pos_ == 'NOUN':\n",
    "        results = search_bird_dbpedia(token.lemma_)\n",
    "        if len(results) > 0:\n",
    "          maybe_matches[token] = results\n",
    "          print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, funciona? Lo que es muy lento y estamos machacando la dbpedia a queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento 3: Cachear / indexar la dbpedia\n",
    "\n",
    "Del intento anterior vamos a coger los resultados de todos los pájaros y lo convertiremos en un diccionario para que nos sea más fácil buscar y solo haremos n queries a la dbpedia. Por supuesto, esta estrategia es solo factible si el conjunto es finito. Como es nuestro caso, va haber n especies de pájaros, pero no va a estar creciendo dia a dia.\n",
    "\n",
    "### Estrategia\n",
    "- Obtener lista de todos los nombres de pájaros.\n",
    "- Con spacy analizaremos la entrada del avistamiento y obtenemos los `noun chunk`.\n",
    "  - Para hacer spacy más rápido vamos a deshabilitar las pipelines que no usemos, que son `lemmatizer` y `ner`.\n",
    "- Con cada `chunk` usando fuzzy-search en la lista de nombres de pájaros para encontrar aquellos chunk que parezcan nombres de pájaros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hemos obtenido los nombres de 10369 pájaros\n",
      "Actenoides\n",
      "African goshawk\n",
      "African pitta\n",
      "African red-eyed bulbul\n",
      "Alcedo\n"
     ]
    }
   ],
   "source": [
    "# Obtener todos los pájaros. Obtenemos las descripciones para intentos posteriores.\n",
    "birds_sparql = s.query(\"\"\"\n",
    "  SELECT DISTINCT *\n",
    "  WHERE {\n",
    "    ?bird a dbo:Bird ;\n",
    "          rdfs:label ?name ;\n",
    "          dbo:abstract ?comment .\n",
    "\n",
    "    filter (!isLiteral(?name) ||\n",
    "            langmatches(lang(?name), \"en\")) .\n",
    "\n",
    "    filter (!isLiteral(?comment) ||\n",
    "            langmatches(lang(?comment), \"en\")) .\n",
    "    \n",
    "  }\n",
    "  limit 10000\n",
    "\"\"\")\n",
    "\n",
    "birds_sparql += s.query(\"\"\"\n",
    "  SELECT DISTINCT *\n",
    "  WHERE {\n",
    "    ?bird a dbo:Bird ;\n",
    "          rdfs:label ?name ;\n",
    "          dbo:abstract ?comment .\n",
    "\n",
    "    filter (!isLiteral(?name) ||\n",
    "            langmatches(lang(?name), \"en\")) .\n",
    "\n",
    "    filter (!isLiteral(?comment) ||\n",
    "            langmatches(lang(?comment), \"en\")) .\n",
    "    \n",
    "  }\n",
    "  limit 10000\n",
    "  offset 10000\n",
    "\"\"\")\n",
    "\n",
    "write(\"../data\", \"birds\", birds_sparql)\n",
    "\n",
    "print(f\"Hemos obtenido los nombres de {len(birds_sparql)} pájaros\")\n",
    "for d in birds_sparql[0:5]:\n",
    "  print(d['name']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos los datos en crudo a un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparql a diccionario\n",
    "remove_parentesis_text = re.compile(r'\\(|\\)')\n",
    "\n",
    "birds = {}\n",
    "for bird in birds_sparql:\n",
    "  bird_name_lower = bird[\"name\"][\"value\"].lower()\n",
    "  key = re.sub(remove_parentesis_text, \"\", str(bird_name_lower))\n",
    "  if key in birds.keys():\n",
    "    print(f\"bird {key} is duplicated.\", birds[key][\"name\"], bird[\"name\"][\"value\"])\n",
    "  birds[key] = {\n",
    "    \"name\": bird[\"name\"][\"value\"],\n",
    "    \"url\": bird[\"bird\"][\"value\"],\n",
    "    \"description\": bird[\"comment\"][\"value\"],\n",
    "  }\n",
    "bird_keys = birds.keys() # buscaremos por las key\n",
    "assert len(birds_sparql) == len(bird_keys) # aseguramos que no hayamos perdido ninguna key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Goliath (Mangalia)',\n",
       " 'url': 'http://dbpedia.org/resource/Goliath_(Mangalia)',\n",
       " 'description': 'Goliath is the name of a crane that is currently located at the Mangalia shipyard in Mangalia, Romania. Formerly, it was part of the Fore River Shipyard in Quincy, Massachusetts.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds[\"goliath mangalia\"] # bueno... la dbpedia tampoco es perfecta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"69f5524ef5e74b7cbcd5f09536783707-0\" class=\"displacy\" width=\"575\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Black-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">billed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">flycatcher</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-69f5524ef5e74b7cbcd5f09536783707-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-69f5524ef5e74b7cbcd5f09536783707-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-69f5524ef5e74b7cbcd5f09536783707-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-69f5524ef5e74b7cbcd5f09536783707-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,91.5 L237,79.5 253,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\", disable=['lemmatizer'])\n",
    "\n",
    "doc = nlp(\"Black-billed flycatcher\")\n",
    "displacy.render(doc, jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el `tokenizer` de spacy nos separa las palabras compuestas con guion.\n",
    "\n",
    "Para solucionarlo vamos a modificar el tokenizer para que no separe las palabras con guion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacer que el tokenizer no separe palabras con guion\n",
    "# https://stackoverflow.com/questions/59993683/how-can-i-get-spacy-to-stop-splitting-both-hyphenated-numbers-and-words-into-sep\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    inf = list(nlp.Defaults.infixes)               # Default infixes\n",
    "    inf.remove(r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\")    # Remove the generic op between numbers or between a number and a -\n",
    "    inf = tuple(inf)                               # Convert inf to tuple\n",
    "    infixes = inf + tuple([r\"(?<=[0-9])[+*^](?=[0-9-])\", r\"(?<=[0-9])-(?=-)\"])  # Add the removed rule after subtracting (?<=[0-9])-(?=[0-9]) pattern\n",
    "    infixes = [x for x in infixes if '-|–|—|--|---|——|~' not in x] # Remove - between letters rule\n",
    "    infix_re = compile_infix_regex(infixes)\n",
    "\n",
    "    return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
    "                                suffix_search=nlp.tokenizer.suffix_search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=nlp.tokenizer.token_match,\n",
    "                                rules=nlp.Defaults.tokenizer_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0e9d775ce11543279130106cdf5c86ad-0\" class=\"displacy\" width=\"400\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Black-billed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">flycatcher</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0e9d775ce11543279130106cdf5c86ad-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0e9d775ce11543279130106cdf5c86ad-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "doc = nlp(\"Black-billed flycatcher\")\n",
    "displacy.render(doc, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genial! A demás conseguimos que `Black-billed` se detecte como adjetivo y no como adjetivo + verbo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'ring-billed gull' in 'ring-billed gull' with score of 100\n",
      "Found 'peregrine falcon' in 'female peregrine falcon' with score of 82\n",
      "['ring-billed gull', 'peregrine falcon']\n"
     ]
    }
   ],
   "source": [
    "# Busqueda de pájaros por fuzzysearch\n",
    "from fuzzywuzzy import fuzz\n",
    "def search_bird_dict(chunk):\n",
    "  best_match = (False, None, 0)\n",
    "  for key in bird_keys:\n",
    "    score = fuzz.ratio(key, chunk)\n",
    "    if score > 80 and score > best_match[-1]:\n",
    "      # print(f\"\\tchunk: '{chunk}' compare '{key}' score: '{score}'\")\n",
    "      best_match = (True, key, score)\n",
    "      break\n",
    "  return best_match\n",
    "\n",
    "def get_nouns(chunk):\n",
    "  only_nouns = []\n",
    "  for token in chunk:\n",
    "    if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\":\n",
    "      only_nouns.append(token.lower_)\n",
    "\n",
    "  if len(only_nouns) > 0:\n",
    "    return \" \".join(only_nouns)\n",
    "  return None\n",
    "\n",
    "maybe_matches = []\n",
    "for text in open(shorebirder_posts_file, \"r\").readlines()[0:5]:\n",
    "  doc = nlp(text)\n",
    "  for chunk in [get_nouns(chunk) for chunk in doc.noun_chunks]:\n",
    "    if chunk != None:\n",
    "      (found, bird_key, score) = search_bird_dict(chunk)\n",
    "      if found:\n",
    "        maybe_matches.append(bird_key)\n",
    "        print(f\"Found '{bird_key}' in '{chunk}' with score of {score}\")\n",
    "          \n",
    "# Test result\n",
    "print(maybe_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos la ontología\n",
    "# pip install Cython owlready2\n",
    "# pip install slugify\n",
    "import Cython\n",
    "from owlready2 import *\n",
    "from slugify import slugify\n",
    "import uuid\n",
    "\n",
    "# Creamos una ontología\n",
    "onto = get_ontology(\"http://avistamiento-aves.org/onto.owl\")\n",
    "onto.destroy()\n",
    "onto = get_ontology(\"http://avistamiento-aves.org/onto.owl\")\n",
    "\n",
    "with onto:\n",
    "  class label(DataProperty):\n",
    "    range = [str]\n",
    "  class match_text(DataProperty):\n",
    "    range = [str]\n",
    "  class match_score(DataProperty):\n",
    "    range = [float]\n",
    "  class dbpedia(DataProperty):\n",
    "    range = [str]\n",
    "  class date(DataProperty):\n",
    "    range = [str]\n",
    "  class position(DataProperty):\n",
    "    range = [str]\n",
    "  class generic_context(DataProperty):\n",
    "    range = [str]\n",
    "\n",
    "  class Bird(Thing):\n",
    "    pass\n",
    "  class Sighting(Thing):\n",
    "    pass\n",
    "\n",
    "  class has_been_seen(ObjectProperty):\n",
    "    domain = [Bird]\n",
    "    range = [Sighting]\n",
    "  class birds_found(ObjectProperty):\n",
    "    domain = [Sighting]\n",
    "    range = [Bird]\n",
    "    inverse_property = has_been_seen\n",
    "\n",
    "# Owl functions\n",
    "def create_sighting(doc):\n",
    "  sighting = Sighting(f\"sighting-{uuid.uuid4()}\")\n",
    "  sighting.text = doc.text\n",
    "  return sighting\n",
    "\n",
    "def register_bird(sighting, bird_key, chunk_nouns, score):\n",
    "  slugify_name = slugify(bird_key, separator=\"_\")\n",
    "  bird_onto = types.new_class(slugify_name, (Bird,))\n",
    "  bird_dict = birds[bird_key]\n",
    "  bird_individual = bird_onto(f\"{slugify_name}-{uuid.uuid4()}\")\n",
    "  bird_individual.label.append(bird_dict[\"name\"])\n",
    "  bird_individual.match_text.append(chunk_nouns)\n",
    "  bird_individual.match_score.append(score)\n",
    "  bird_individual.dbpedia.append(bird_dict[\"url\"])\n",
    "  sighting.birds_found.append(bird_individual)\n",
    "  return bird_individual\n",
    "\n",
    "def add_context(individual, name, type):\n",
    "  if type == \"DATE\":\n",
    "    individual.date.append(name)\n",
    "  if type == \"NORP\" or type == \"GPE\":\n",
    "    individual.position.append(name)\n",
    "  else:\n",
    "    individual.generic_context.append(name)\n",
    "\n",
    "# avistamiento\n",
    "class sighting_class:\n",
    "  namespace = onto\n",
    "\n",
    "  def __init__(self, doc):\n",
    "    self.doc = doc\n",
    "    self.birds = []\n",
    "    self.contexts = []\n",
    "\n",
    "  def add_bird(self, bird):\n",
    "    self.birds.append(bird)\n",
    "\n",
    "  def add_context(self, context):\n",
    "    self.contexts.append(context)\n",
    "\n",
    "class bird_class:\n",
    "  def __init__(self, bird_key, text_found, similarity):\n",
    "    self.bird_key = bird_key\n",
    "    self.text_found = text_found\n",
    "    self.similarity = similarity\n",
    "  def __repr__(self):\n",
    "        return self.bird_key\n",
    "\n",
    "# https://stackoverflow.com/questions/50792574/what-are-the-supported-date-and-time-formats-in-spacy-2-0/50794950#50794950\n",
    "class context_class:\n",
    "  def __init__(self, ent):\n",
    "    self.ent = ent\n",
    "    self.name = str(ent)\n",
    "    self.type = ent.label_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:29<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/posts/shorebirder_results_log_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Found 'ring-billed gull' in 'ring-billed gull' with score of 100\\n\",\n",
       " \"Found 'peregrine falcon' in 'female peregrine falcon' with score of 82\\n\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcular para todas las review\n",
    "trace = []\n",
    "for text in tqdm.tqdm(open(shorebirder_posts_file, \"r\").readlines()):\n",
    "  doc = nlp(text)\n",
    "  sighting = create_sighting(doc)\n",
    "\n",
    "  for chunk in doc.noun_chunks:\n",
    "    chunk_nouns = get_nouns(chunk)\n",
    "    if chunk_nouns != None:\n",
    "      (found, bird_key, score) = search_bird_dict(chunk_nouns)\n",
    "      if found:\n",
    "        bird_individual = register_bird(sighting, bird_key, chunk_nouns, score)\n",
    "        trace.append(f\"Found '{bird_key}' in '{chunk_nouns}' with score of {score}\")\n",
    "        for ent in chunk.ents:\n",
    "          add_context(bird_individual, str(ent), ent.label_)\n",
    "      else:\n",
    "        for ent in chunk.ents:\n",
    "          add_context(sighting, str(ent), ent.label_)\n",
    "\n",
    "onto.save(file=\"../owl/avistamiento-aves.xml\", format = \"rdfxml\")\n",
    "log_result = write(data_posts_path, \"shorebirder_results_log_3\", trace)\n",
    "print(log_result)\n",
    "open(log_result, \"r\", encoding=\"utf-8\").readlines()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primera versión funcional sin machacar a la dbpedia. Pero sigue siendo muy lento. Vamos a seguir probando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Nueva pipeline [entity_ruler](https://spacy.io/api/entityruler)\n",
    "\n",
    "En esta aproximación vamos a añadir una pipe más al nlp `en_core_web_lg` pre-entrenado de spacy. Para ello necesitamos hacer una lista de todos los patterns que queramos poner. Es decir, debemos introducir los nombres de los pájaros que queremos que se detecten como patterns y añadir la nueva pipe al nlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando entity_ruler https://spacy.io/usage/rule-based-matching#entityruler\n",
    "from spacy.lang.en import English\n",
    "\n",
    "tag = \"BIRD\"\n",
    "\n",
    "# init blank nlp\n",
    "nlp = English()\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "# Añadir los nombres de pájaros\n",
    "patterns = []\n",
    "for key in bird_keys:\n",
    "  bird = birds[key]\n",
    "  doc = nlp(bird[\"name\"])\n",
    "  pattern = []\n",
    "  for token in doc:\n",
    "    pattern.append({\n",
    "      \"LOWER\": token.lower_\n",
    "    })\n",
    "\n",
    "  patterns.append({\n",
    "    \"label\": tag,\n",
    "    \"pattern\": pattern,\n",
    "    \"id\": key\n",
    "  })\n",
    "\n",
    "# add entity_ruler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "with nlp.select_pipes(enable=\"tagger\"):\n",
    "  ruler.add_patterns(patterns)\n",
    "\n",
    "nlp.to_disk(\"../models/entity_ruler/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">that feeding gulls flock continued to produce by sucking in passers by. at one point a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bonaparte's gull\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BIRD</span>\n",
       "</mark>\n",
       " got in on the action, and a flock of 21 common terns appeared from the east and eventually settled into that flock.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entity_ruler']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"that feeding gulls flock continued to produce by sucking in passers by. at one point a Bonaparte's gull got in on the action, and a flock of 21 common terns appeared from the east and eventually settled into that flock.\")\n",
    "displacy.render(doc, jupyter=True, style=\"ent\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 63.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gull', 'ring-billed gull', 'peregrine falcon', 'gull', 'gull', 'gull', 'iceland gull', 'american bittern', 'hawk', 'little blue heron', 'glossy ibis', 'yellow-bellied sapsucker', 'scarlet tanager', 'gull', \"bonaparte's gull\", 'least sandpiper', 'saltmarsh sparrow', \"nelson's sparrow\", 'marsh wren', 'american bittern', 'puna plover', 'hummingbird', 'collared inca', 'shining sunbeam', 'chestnut-crested cotinga', 'cock-of-the-rock', 'solitary eagle', 'lyre-tailed nightjar', 'andean cock-of-the-rock', 'wire-crested thorntail', 'hummingbird', 'white-throated toucan', 'green honeycreeper', 'yellow-bellied dacnis', 'owl', 'nighthawk', 'parrot', 'hoatzin', 'elaenia', 'seabird', 'cinclodes', 'purple sandpiper', 'humboldt penguin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calcular para todas las review\n",
    "maybe_matches = []\n",
    "for text in tqdm.tqdm(open(shorebirder_posts_file, \"r\").readlines()):\n",
    "  doc = nlp(text)\n",
    "  for ent in doc.ents:\n",
    "    if ent.label_ == \"BIRD\" and ent.ent_id_ != \"\":\n",
    "      maybe_matches.append(ent.ent_id_)\n",
    "\n",
    "print(maybe_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hemos encontrado 37 pájaros distintos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hemos encontrado 'Least sandpiper' con entrada en la dbpedia 'http://dbpedia.org/resource/Least_sandpiper'.\\n\",\n",
       " \"Hemos encontrado 'Chestnut-crested cotinga' con entrada en la dbpedia 'http://dbpedia.org/resource/Chestnut-crested_cotinga'.\\n\",\n",
       " \"Hemos encontrado 'Scarlet tanager' con entrada en la dbpedia 'http://dbpedia.org/resource/Scarlet_tanager'.\\n\",\n",
       " \"Hemos encontrado 'Humboldt penguin' con entrada en la dbpedia 'http://dbpedia.org/resource/Humboldt_penguin'.\\n\",\n",
       " \"Hemos encontrado 'Saltmarsh sparrow' con entrada en la dbpedia 'http://dbpedia.org/resource/Saltmarsh_sparrow'.\\n\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pintar y guardar resultado\n",
    "result_lines = []\n",
    "for bird_key in set(maybe_matches):\n",
    "  bird = dict(birds[bird_key])\n",
    "  name = bird[\"name\"]\n",
    "  url = bird[\"url\"]\n",
    "  result_lines.append(f\"Hemos encontrado '{name}' con entrada en la dbpedia '{url}'.\")\n",
    "\n",
    "result_lines_file = write(data_posts_path, \"shorebirder_results_4\", result_lines)\n",
    "print(f\"Hemos encontrado {len(result_lines)} pájaros distintos\")\n",
    "open(result_lines_file, \"r\").readlines()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejoramos mucho la velocidad por una cantidad aceptable de reconocimiento de aves. Pero no nos detecta todas las que conseguimos detectar en el `intento 3`. Esto es porque la capa de entity_ruler no es parte del modelo sino pattern matching. por ello no es capaz de encontrar las formas en plural de las aves que el intento 3 si encuentra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenar ner Spacy\n",
    "\n",
    "En este apartado vamos a centrarnos en mejorar la detección de spacy entrenando un modelo de clasificación. Las frases de entreno las cogeremos de las descripciones de la dbpedia. Los datos de entreno deberán estar compuestos de una frase más las posiciones de los nombres de pájaros. Para reconocer los pájaros que aparecen en las descripciones usaremos el `entity ruler` del apartado anterior. Al usar el entity ruler para esta tarea vamos a suponer que en la dbpedia no hay faltas de ortografía en las descripciones para que los pájaros sean identificables, y su nombre aparezca al menos una vez.\n",
    "\n",
    "La [pipeline](https://spacy.io/usage/spacy-101#pipelines) de spacy que se encarga de etiquetar las entities se llama [Entity Recognizer](https://spacy.io/api/entityrecognizer) o `ner`. Según la documentación de spacy sobre como [entrenar](https://spacy.io/usage/training) un modelo, primero necesitamos las frases de entreno correctamente etiquetadas, vectores por palabra a etiquetar y un fichero de configuración con las pipelines a entrenar.\n",
    "\n",
    "La generación de frases de entreno usaremos el 100% de frases para train y 20% para test (subconjunto de train). He decidido \"correr el riesgo\" de over-fitting del modelo a la de no registrar pájaros al modelo. He tomado esta decisión dada las escasas frases/pájaro que podemos obtener de la dbpedia.\n",
    "\n",
    "Para que ner pueda reconocer y comparar las aves vamos a tener que generar [vectores](https://spacy.io/usage/linguistic-features#vectors-similarity). Sabemos que el nlp de spacy no genera vectores para palabras fuera del modelo, o en el caso de `en_core_web_sm` directamente no tiene. Para ello, la generación de vectores se va a realizar mediante la librería [gensim](https://radimrehurek.com/gensim/) y la técnica [Word2Vec](https://es.wikipedia.org/wiki/Word2vec) como sugieren en la documentación de spacy.\n",
    "\n",
    "El fichero de configuración guardado en `src/birds_config.cfg` se ha generado usando la [herramienta web](https://spacy.io/usage/training#quickstart) que proporciona spacy seleccionando `ner` + `cpu` + `efficiency`. Ner, porque es la pipeline que queremos entrenar. Cpu, porque he tenido problemas para compilar pytorch para usar la gpu y es una opción más compatible. Efficiency porque nosotros le proporcionaremos los vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The type species is Hombron's kingfisher (Actenoides hombroni) [(21, 41, \"hombron's kingfisher\"), (43, 53, 'actenoides')]\n",
      "----------\n",
      " A molecular study published in 2017 found that the genus Actenoides, as currently defined, is paraphyletic [(58, 68, 'actenoides')]\n",
      "----------\n",
      " The glittering kingfisher in the monotypic genus Caridonax is a member of the clade containing the species in the genus Actenoides [(5, 26, 'glittering kingfisher'), (121, 131, 'actenoides')]\n",
      "----------\n",
      " Green-backed kingfisher (Actenoides monachus) \n",
      " [(1, 24, 'green-backed kingfisher'), (26, 36, 'actenoides')]\n",
      "----------\n",
      " Black-headed kingfisher (Actenoides monachus capucinus) \n",
      " [(1, 24, 'black-headed kingfisher'), (26, 36, 'actenoides')]\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Transformar las descripciones en datos de entreno y test para spacy\n",
    "import gensim\n",
    "import random\n",
    "import unicodedata\n",
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# init the \"base nlp\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# add custom tokenizer\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "# add entity_ruler \n",
    "entity_ruler = spacy.load(\"../models/entity_ruler\")\n",
    "nlp.add_pipe(\"entity_ruler\", source=entity_ruler, before=\"ner\")\n",
    "\n",
    "def get_vector(ent):\n",
    "  if ent.has_vector:\n",
    "    return ent.vector\n",
    "  else:\n",
    "    return gensim.models.Word2Vec(ent, min_count = 1,size = 200, window = 6, sg=0)\n",
    "\n",
    "# build training sentences\n",
    "training_data = [\n",
    "  # (\"Tokyo Tower is 333m tall.\", [(0, 11, \"BUILDING\")], tag/label, vector), # example\n",
    "]\n",
    "for key in tqdm.tqdm(bird_keys):\n",
    "  bird = birds[key]\n",
    "  bird_name = bird[\"name\"]\n",
    "\n",
    "  if len(bird_name) == 0:\n",
    "    continue\n",
    "  \n",
    "  bird_name = re.sub(remove_parentesis_text, \"\", str(bird_name))\n",
    "  description = bird[\"description\"]\n",
    "\n",
    "  for train_sentence in re.split(sentence_endings, description):\n",
    "    # usamos el reconocimiento de aves anterior para encontrar las aves\n",
    "    # suponemos que la dbpedia tiene las aves bien identificadas\n",
    "    doc = nlp(train_sentence)\n",
    "    positions = []\n",
    "    for ent in doc.ents:\n",
    "      if ent.label_ == tag and ent.ent_id_ != \"\":\n",
    "        vector = get_vector(ent)\n",
    "        positions.append((ent.start_char, ent.end_char, ent.ent_id_, vector))\n",
    "\n",
    "    if len(positions) > 0:\n",
    "      training_data.append(\n",
    "        (train_sentence, positions)\n",
    "      )\n",
    "\n",
    "def outer_join(lst1, lst2):\n",
    "  lst2_names = [name for name, annotations in lst2]\n",
    "  lst3 = [(name, annotations) for name, annotations in lst1 if not name in lst2_names]\n",
    "  return lst3\n",
    "\n",
    "test_data = random.sample(training_data, k=round(len(training_data)*0.2))\n",
    "\n",
    "# si quitamos las frases de test del modelo de entreno luego no vamos a poder detectar esas aves... no es ideal pero tampoco podemos asegurar que tengamos frases para todos los pájaros\n",
    "training_data = outer_join(training_data, test_data) \n",
    "\n",
    "for text, annotations in training_data[0:5]:\n",
    "  print(text, [(a, b, c) for a, b, c, d in annotations])\n",
    "  print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 185.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build train set\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "nlp = English()\n",
    "# no separar por \"-\"\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "# añadir entity_ruler del apartado anterior\n",
    "entity_ruler = spacy.load(\"../models/entity_ruler\")\n",
    "nlp.add_pipe(\"entity_ruler\", source=entity_ruler)\n",
    "\n",
    "def build_db(nlp, data):\n",
    "  skips = 0\n",
    "  # the DocBin will store the example documents\n",
    "  db = DocBin()\n",
    "  for text, annotations in tqdm.tqdm(data):\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label, vector in annotations:\n",
    "      span = doc.char_span(start, end, label=label, vector=vector)\n",
    "      if span is None:\n",
    "        skips += 1\n",
    "      else:\n",
    "        ents.append(span)\n",
    "    filtered_ents = filter_spans(ents)\n",
    "    doc.ents = filtered_ents\n",
    "    db.add(doc)\n",
    "  return (db, skips)\n",
    "\n",
    "(db, skips) = build_db(nlp, training_data)\n",
    "print(f\"Skipped {skips} entries\")\n",
    "db.to_disk(\"./birds_train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 136.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build test set\n",
    "(db, skips) = build_db(nlp, test_data)\n",
    "print(f\"Skipped {skips} entries\")\n",
    "db.to_disk(\"./birds_test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model https://spacy.io/usage/training\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# train the model\n",
    "!python -m spacy init fill-config birds_config.cfg config.cfg\n",
    "!python -m spacy train config.cfg --output ../models/custom_ner --paths.train ./birds_train.spacy --paths.dev ./birds_test.spacy\n",
    "\n",
    "## powershell: (launch from console to use all cpu cores)\n",
    "# $env:KMP_DUPLICATE_LIB_OK = \"True\"\n",
    "# python -m spacy init fill-config birds_config.cfg config.cfg\n",
    "# python -m spacy train config.cfg --output ../models/custom_ner --paths.train ./birds_train.spacy --paths.dev ./birds_test.spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'entity_ruler', 'ner']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    golden-fronteds fulvetta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">grey honeyeater</span>\n",
       "</mark>\n",
       " (Schoeniparus variegaticeps), also known as the gold-fronted fulvetta, is a species of bird in the family Pellorneidae</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    African goshawk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BIRD</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Accipiter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BIRD</span>\n",
       "</mark>\n",
       " tachiro) is a species of African bird of prey in the genus \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Accipiter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BIRD</span>\n",
       "</mark>\n",
       " which is the type genus of the family Accipitridae.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The type species is \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hombron's kingfisher\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BIRD</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Actenoides\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BIRD</span>\n",
       "</mark>\n",
       " hombroni)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# juntamos el entreno previo con las patterns\n",
    "nlp = spacy.load(\"../models/custom_ner/model-best\")\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "entity_ruler = spacy.load(\"../models/entity_ruler\")\n",
    "nlp.add_pipe(\"entity_ruler\", source=entity_ruler, before=\"ner\")\n",
    "\n",
    "# ner = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.add_pipe(\"ner\", name=\"base_ner\", source=ner, after=\"ner\")\n",
    "\n",
    "# comprobamos las pipes\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# try\n",
    "doc = nlp(\"The golden-fronteds fulvetta (Schoeniparus variegaticeps), also known as the gold-fronted fulvetta, is a species of bird in the family Pellorneidae\")\n",
    "displacy.render(doc, jupyter=True, style=\"ent\")\n",
    "\n",
    "doc = nlp(\"The African goshawk (Accipiter tachiro) is a species of African bird of prey in the genus Accipiter which is the type genus of the family Accipitridae.\")\n",
    "displacy.render(doc, jupyter=True, style=\"ent\")\n",
    "\n",
    "doc = nlp(\"The type species is Hombron's kingfisher (Actenoides hombroni)\")\n",
    "displacy.render(doc, jupyter=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:11<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid=False, accuracy=0, alt='None' Hemos encontrado 'bridgeport' con entrada en la dbpedia [Booby]'http://dbpedia.org/resource/Booby'.\n",
      "valid=False, accuracy=0, alt='None' Hemos encontrado 'isla pucusana, home to' con entrada en la dbpedia [African black swift]'http://dbpedia.org/resource/African_black_swift'.\n",
      "valid=False, accuracy=0, alt='None' Hemos encontrado 'fun event' con entrada en la dbpedia [Red grouse]'http://dbpedia.org/resource/Red_grouse'.\n",
      "valid=False, accuracy=0, alt='None' Hemos encontrado 'aware' con entrada en la dbpedia [Hummingbird]'http://dbpedia.org/resource/Hummingbird'.\n",
      "valid=False, accuracy=0, alt='None' Hemos encontrado 'increasing east winds' con entrada en la dbpedia [Sickle-billed vanga]'http://dbpedia.org/resource/Sickle-billed_vanga'.\n",
      "valid=False, accuracy=0, alt='None' Hemos encontrado 'boat ride' con entrada en la dbpedia [Spotted tanager]'http://dbpedia.org/resource/Spotted_tanager'.\n",
      "Hemos encontrado 37 pájaros distintos de 43. 6 encontrados con ner y 43 encontrados con entity ruler. Ha habido 6 falsos casos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hemos encontrado 'ring-billed gull' con entrada en la dbpedia [Ring-billed gull]'http://dbpedia.org/resource/Ring-billed_gull'.\\n\",\n",
       " \"Hemos encontrado 'andean cock-of-the-rock' con entrada en la dbpedia [Andean cock-of-the-rock]'http://dbpedia.org/resource/Andean_cock-of-the-rock'.\\n\",\n",
       " \"Hemos encontrado 'humboldt penguin' con entrada en la dbpedia [Humboldt penguin]'http://dbpedia.org/resource/Humboldt_penguin'.\\n\",\n",
       " \"Hemos encontrado 'puna plover' con entrada en la dbpedia [Puna plover]'http://dbpedia.org/resource/Puna_plover'.\\n\",\n",
       " \"Hemos encontrado 'solitary eagle' con entrada en la dbpedia [Solitary eagle]'http://dbpedia.org/resource/Solitary_eagle'.\\n\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcular para todas las review\n",
    "found_with_ruler = 0\n",
    "found_with_ner = 0\n",
    "maybe_matches = []\n",
    "for text in tqdm.tqdm(open(shorebirder_posts_file, \"r\").readlines()):\n",
    "  doc = nlp(text)\n",
    "  # if len(doc.ents) > 0:\n",
    "  #   displacy.render(doc, jupyter=True, style=\"ent\")\n",
    "  for ent in doc.ents:\n",
    "    if ent.label_ == \"BIRD\":\n",
    "      found_with_ruler += 1\n",
    "      maybe_matches.append((ent.ent_id_, str(ent)))\n",
    "    else:\n",
    "      found_with_ner += 1\n",
    "      maybe_matches.append((ent.label_, str(ent)))\n",
    "     \n",
    "invalid_birds = 0\n",
    "# Pintar y guardar resultado\n",
    "result_lines = []\n",
    "for bird_key, original in set(maybe_matches):\n",
    "  bird = dict(birds[bird_key])\n",
    "  name = bird[\"name\"]\n",
    "  url = bird[\"url\"]\n",
    "  (valid, alt_key, accuracy) = search_bird_dict(original)\n",
    "  if valid:\n",
    "    result_lines.append(f\"Hemos encontrado '{original}' con entrada en la dbpedia [{name}]'{url}'.\")\n",
    "  else:\n",
    "    invalid_birds += 1\n",
    "    print(f\"valid={valid}, accuracy={accuracy}, alt='{alt_key}' Hemos encontrado '{original}' con entrada en la dbpedia [{name}]'{url}'.\")\n",
    "\n",
    "result_lines_file = write(data_posts_path, \"shorebirder_results_5\", result_lines)\n",
    "print(f\"Hemos encontrado {len(result_lines)} pájaros distintos de {found_with_ner+found_with_ruler-invalid_birds}.\",\n",
    "  f\"{found_with_ner} encontrados con ner y {found_with_ruler} encontrados con entity ruler.\",\n",
    "  f\"Ha habido {invalid_birds} falsos casos\")\n",
    "open(result_lines_file, \"r\", encoding=\"utf-8\").readlines()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `entity_recognizer` o `ner` mejora los resultados del apartado anterior pero no la precisión del apartado 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el resultado en una Ontología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Cython owlready2\n",
    "from owlready2 import *\n",
    "\n",
    "#Creamos una ontología\n",
    "onto = get_ontology(\"http://avistamiento-aves.org/onto.owl\")\n",
    "\n",
    "class Bird(Thing):\n",
    "  namespace = onto\n",
    "\n",
    "from slugify import slugify\n",
    "\n",
    "found_birds = json.load(open(\"../data/results/shorebirder_results_3.json\", \"r\"))\n",
    "\n",
    "for bird in found_birds:\n",
    "  slugify_name = slugify(bird[\"name\"], separator=\"_\")\n",
    "  bird_class = types.new_class(slugify_name, (Bird,))\n",
    "\n",
    "onto.save(file=\"../owl/avistamiento-aves.xml\", format = \"rdfxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a poblar nuestra ontologia con los datos obtenidos en el apartado 3, que ha resultado ser la forma más precisa de obtener los pájaros."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f49206fcf84a9145e7e21228cbafa911d1ac18292303b01e865d8267a9c448f7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
